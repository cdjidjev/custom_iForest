{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ipv4, scan_id, port, service, anomaly]\n",
      "Index: []\n",
      "anomalous_ips: []\n",
      "2 PAIRS\n",
      "Index(['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'], dtype='object')\n",
      "Anomalous ip: 107.48.249.14\n",
      "Anomalous ip: 162.15.11.13\n",
      "             ipv4  scan_id              port                 service  anomaly\n",
      "58  107.48.249.14       58  [53, 80, 21, 25]  [FTP, SMTP, DNS, HTTP]        1\n",
      "59  107.48.249.14       59  [53, 80, 21, 25]  [FTP, SMTP, DNS, HTTP]        1\n",
      "98   162.15.11.13       98  [25, 80, 53, 21]  [FTP, SMTP, DNS, HTTP]        1\n",
      "99   162.15.11.13       99  [25, 80, 53, 21]  [FTP, SMTP, DNS, HTTP]        1\n",
      "anomalous_ips: ['107.48.249.14' '162.15.11.13']\n",
      "2 PAIRS\n",
      "Index(['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'], dtype='object')\n",
      "Anomalous ip: 86.157.128.108\n",
      "              ipv4  scan_id              port                 service  anomaly\n",
      "38  86.157.128.108       38  [53, 80, 21, 25]  [FTP, SMTP, DNS, HTTP]        1\n",
      "39  86.157.128.108       39  [53, 80, 21, 25]  [FTP, SMTP, DNS, HTTP]        1\n",
      "anomalous_ips: ['86.157.128.108']\n",
      "2 PAIRS\n",
      "Index(['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'], dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [ipv4, scan_id, port, service, anomaly]\n",
      "Index: []\n",
      "anomalous_ips: []\n",
      "2 PAIRS\n",
      "Index(['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'], dtype='object')\n",
      "Empty DataFrame\n",
      "Columns: [ipv4, scan_id, port, service, anomaly]\n",
      "Index: []\n",
      "anomalous_ips: []\n",
      "2 PAIRS\n",
      "Index(['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'], dtype='object')\n",
      "\n",
      "Average Performance Metrics:\n",
      "---------------------------------------------------------------\n",
      "           Custom iForest  iForest Flattened  iForest Pairs  \\\n",
      "Precision             0.1                0.0          0.120   \n",
      "Recall                0.1                0.0          0.400   \n",
      "F2-Score              0.1                0.0          0.265   \n",
      "\n",
      "           iForest Summarization  \n",
      "Precision                    0.0  \n",
      "Recall                       0.0  \n",
      "F2-Score                     0.0  \n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import generate_data_functions\n",
    "reload(generate_data_functions)\n",
    "from generate_data_functions import *\n",
    "\n",
    "from importlib import reload\n",
    "import grouped_iForest_functions\n",
    "reload(grouped_iForest_functions)\n",
    "from grouped_iForest_functions import *\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statistics import mean\n",
    "\n",
    "def summarization(df):        \n",
    "    # Summarize the data by grouping by IP address and counting port and service occurrences\n",
    "    df_sum = summarize_features(df)\n",
    "    print(df.columns)\n",
    "    '''print(df_sum.columns)\n",
    "    print('df_sum',df_sum)'''\n",
    "\n",
    "    '''S = set(df_sum[df_sum['anomaly'] == 1]['ip_id'].unique())\n",
    "    df_filtered = df_sum[df_sum['ip_id'].isin(S)]\n",
    "    #print(df_filtered.drop(columns = ['ip_id']))'''\n",
    "\n",
    "    df_sum = df_sum.rename(str,axis=\"columns\")\n",
    "    all_columns = df_sum.columns.tolist()\n",
    "    column_to_exclude = ['ipv4', 'anomaly']\n",
    "    features = [col for col in all_columns if col not in column_to_exclude]\n",
    "\n",
    "    regForest_sum = IsolationForest(random_state=0)\n",
    "    regForest_sum.fit(df_sum[features])\n",
    "    regForest_sum_labels = regForest_sum.predict(df_sum[features])\n",
    "    regForest_sum_scores = regForest_sum.decision_function(df_sum[features])\n",
    "    df_sum['anomaly_score'] = regForest_sum_scores\n",
    "\n",
    "    sum_anomaly_dict = {}\n",
    "\n",
    "    # Populate the dictionary with IP addresses and their anomaly scores\n",
    "    for index, row in df_sum.iterrows():\n",
    "        ipv4 = row['ipv4']\n",
    "        anomaly_score = row['anomaly_score']\n",
    "        sum_anomaly_dict[ipv4] = anomaly_score\n",
    "    return sum_anomaly_dict\n",
    "\n",
    "def pairs_anomaly(df):\n",
    "    # Run Data Version (IP-port pairs) 2\n",
    "    # No services in this data version\n",
    "    print('2 PAIRS')\n",
    "\n",
    "    df_pairs = pairs(df)\n",
    "    #print(\"df_pairs\", df_pairs)\n",
    "    # Display the feature matrix\n",
    "    all_columns = df_pairs.columns.tolist()\n",
    "\n",
    "    #Specify the column to exclude\n",
    "    column_to_exclude = ['ipv4', 'anomaly']\n",
    "\n",
    "    # Create a new list excluding the specified column\n",
    "    features = [col for col in all_columns if col not in column_to_exclude]\n",
    "    #print('features:', features)\n",
    "    regForest_pairs = IsolationForest(random_state=0)\n",
    "    regForest_pairs.fit(df_pairs[features])\n",
    "    regForest_pairs_labels = regForest_pairs.predict(df_pairs[features])\n",
    "    regForest_pairs_scores = regForest_pairs.decision_function(df_pairs[features])  \n",
    "    df_pairs['anomaly_score'] = regForest_pairs_scores\n",
    "\n",
    "    # Group by 'ipv4' and sum anomaly scores\n",
    "    anomalies_sum = df_pairs.groupby('ipv4')['anomaly_score'].sum()\n",
    "    anomalies_count = df_pairs['ipv4'].value_counts()\n",
    "\n",
    "    anomalies_avg = anomalies_sum / anomalies_count\n",
    "\n",
    "    # Sort anomalies by their average score\n",
    "    sorted_anomalies_avg = anomalies_avg.sort_values()\n",
    "\n",
    "    # Create the dictionary to store the results\n",
    "    pairs_anomaly_dict = {}\n",
    "\n",
    "    # Populate the dictionary with IP addresses and their anomaly scores\n",
    "    for ipv4, anomaly_score in sorted_anomalies_avg.items():\n",
    "        pairs_anomaly_dict[ipv4] = anomaly_score\n",
    "    return pairs_anomaly_dict\n",
    "\n",
    "def cust_iforest_anomaly(df):\n",
    "    # prepocesses the data by flattening it and separating IPs into octets\n",
    "    features_flat = preprocess_customiForest(df)\n",
    "    custForest_flat = CustomIsolationForest(ipv4_index=0, n_estimators=2, random_state=0, df=df)\n",
    "    custForest_flat.fit(features_flat)\n",
    "\n",
    "#*********** HERE IS WHERE YOU CAN CHANGE THE MIN_SCORE TO TRUE OR FALSE *************\n",
    "    #if min_score = False, iForest will determine the anoamly by taking the average score rather than the lowest (most anaomalous) score\n",
    "    custForest_flat_labels = custForest_flat.predict(features_flat, min_score=True)\n",
    "    custForest_flat_scores = custForest_flat.decision_function(features_flat)\n",
    "    return custForest_flat_scores\n",
    "\n",
    "def flattened(df):\n",
    "    # Run Data Version (original - flattened) 1\n",
    "    features_flat = preprocess_customiForest(df)\n",
    "    #print('features_flat:', features_flat)\n",
    "    regForest_flat = IsolationForest(random_state=0)\n",
    "    regForest_flat.fit(features_flat)\n",
    "    regForest_flat_labels = regForest_flat.predict(features_flat)\n",
    "    regForest_flat_scores = regForest_flat.decision_function(features_flat)    \n",
    "    features_flat['anomaly_score'] = regForest_flat_scores\n",
    "\n",
    "    # Group by 'ipv4' and sum anomaly scores\n",
    "    features_flat['ipv4'] = features_flat[['octet1', 'octet2', 'octet3', 'octet4']].astype(str).agg('.'.join, axis=1)\n",
    "    anomalies_sum = features_flat.groupby('ipv4')['anomaly_score'].sum().reset_index()\n",
    "    anomalies_count = features_flat['ipv4'].value_counts().reset_index(name='count')\n",
    "    merged = pd.merge(anomalies_sum, anomalies_count, on='ipv4')\n",
    "    anomalies_avg = merged['anomaly_score'] / merged['count']\n",
    "    \n",
    "    reg_anomaly_dict = {}\n",
    "\n",
    "    # Populate the dictionary with IP addresses and their anomaly scores\n",
    "    for ipv4, anomaly_score in anomalies_avg.items():\n",
    "        reg_anomaly_dict[ipv4] = anomaly_score\n",
    "    return reg_anomaly_dict\n",
    "\n",
    "def calculate_f2_score(true_anomalous_ips, predicted_anomalous):\n",
    "    \"\"\"\n",
    "    Calculates the F2-Score based on true anomalous IPs and predicted anomalous IPs.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_anomalous_ips (list): List of true anomalous IP addresses.\n",
    "    - predicted_anomalous (list of tuples): List of (IP, score) for IPs flagged as anomalous.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The F2-Score for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert inputs to sets of IPs for comparison\n",
    "    true_anomalous_set = set(true_anomalous_ips)\n",
    "    predicted_anomalous_set = set(ip for ip, score in predicted_anomalous)\n",
    "    \n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = len(true_anomalous_set & predicted_anomalous_set)\n",
    "    fp = len(predicted_anomalous_set - true_anomalous_set)\n",
    "    fn = len(true_anomalous_set - predicted_anomalous_set)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Calculate F2-Score with beta = 2\n",
    "    f2_score = (1 + 2**2) * (precision * recall) / (2**2 * precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return f2_score\n",
    "\n",
    "def calculate_metrics(true_anomalous_ips, predicted_anomalous):\n",
    "    \"\"\"\n",
    "    Calculates Precision, Recall, and F2-Score based on true and predicted anomalous IPs.\n",
    "    \n",
    "    Parameters:\n",
    "    - true_anomalous_ips (list): List of true anomalous IP addresses\n",
    "    - predicted_anomalous (list of tuples): List of (IP, score) for IPs flagged as anomalous\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (precision, recall, f2_score)\n",
    "    \"\"\"\n",
    "    true_anomalous_set = set(true_anomalous_ips)\n",
    "    predicted_anomalous_set = set(ip for ip, score in predicted_anomalous)\n",
    "    \n",
    "    tp = len(true_anomalous_set & predicted_anomalous_set)\n",
    "    fp = len(predicted_anomalous_set - true_anomalous_set)\n",
    "    fn = len(true_anomalous_set - predicted_anomalous_set)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    f2_score = (1 + 2**2) * (precision * recall) / (2**2 * precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f2_score\n",
    "\n",
    "typical_service_port_map = {\n",
    "    'FTP': 21,\n",
    "    'SMTP': 25,\n",
    "    'DNS': 53,\n",
    "    'HTTP': 80\n",
    "    }\n",
    "    #'POP3': 110,\n",
    "    #'IMAP': 143,\n",
    "    #'MYSQL': 3306,\n",
    "    #'SSH': 22\n",
    "#}\n",
    "\n",
    "# region parameters\n",
    "num_repetitions = 5\n",
    "seeds = range(num_repetitions)\n",
    "num_ips=5\n",
    "num_scans_per_ip=20\n",
    "anomaly_rate=0.2\n",
    "anomalous_scan_prob = 0.1\n",
    "# endregion\n",
    "\n",
    "all_exp = [] # List to store all experiments\n",
    "# Lists to store metrics for each method\n",
    "metrics_custom = {'precision': [], 'recall': [], 'f2': []}\n",
    "metrics_reg = {'precision': [], 'recall': [], 'f2': []}\n",
    "metrics_pairs = {'precision': [], 'recall': [], 'f2': []}\n",
    "metrics_sum = {'precision': [], 'recall': [], 'f2': []}\n",
    "\n",
    "# Loop over seeds\n",
    "for seed in seeds:\n",
    "    # Set the random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # region generate the data\n",
    "    df = generate_scan_data_with_variance(num_ips, num_scans_per_ip, typical_service_port_map, anomaly_rate, anomalous_scan_prob, seed)\n",
    "\n",
    "    S = set(df[df['anomaly'] == 1]['ip_id'].unique())\n",
    "    df_filtered = df[df['ip_id'].isin(S) & df['anomaly'] == 1]\n",
    "    print(df_filtered.drop(columns = ['ip_id']))\n",
    "\n",
    "    # Add some hand written anomalies to the data\n",
    "    '''anomalous_scans = [\n",
    "    ['198.51.100.1', 0, 0, [80, 22, 21], ['HTTP', 'SSH', 'FTP'], 0],\n",
    "    ['198.51.100.1', 0, 1, [143, 3306], ['IMAP', 'MYSQL'], 0],\n",
    "    ['198.51.100.1', 0, 2, [80, 143], ['HTTP', 'IMAP'], 0],\n",
    "    ['198.51.100.1', 0, 3, [22, 110], ['SSH', 'POP3'], 0],\n",
    "    ['198.51.100.1', 0, 4, [53, 3306], ['DNS', 'MYSQL'], 0],\n",
    "    ['198.51.100.1', 0, 5, [80, 3306], ['HTTP', 'MYSQL'], 1], # Anomaly: MYSQL on port 80\n",
    "    ['198.51.100.1', 0, 6, [21, 143], ['FTP', 'IMAP'], 1],  # Anomaly: IMAP on port 21\n",
    "    ['198.51.100.1', 0, 7, [22, 53], ['SSH', 'DNS'], 0],\n",
    "    ['198.51.100.1', 0, 8, [110, 3306], ['POP3', 'MYSQL'], 0],\n",
    "    ['198.51.100.1', 0, 9, [21, 143], ['FTP', 'IMAP'], 0]\n",
    "]\n",
    "    \n",
    "    anomalous_df = pd.DataFrame(anomalous_scans, columns=['ipv4', 'ip_id', 'scan_id', 'port', 'service', 'anomaly'])\n",
    "\n",
    "    df = pd.concat([df, anomalous_df], ignore_index=True)'''\n",
    "    \n",
    "    anomalous_ips = df[df['anomaly'] == 1]['ipv4'].unique()\n",
    "    print('anomalous_ips:', anomalous_ips)\n",
    "    # endregion \n",
    "\n",
    "    # region compute anomalies\n",
    "    custForest_flat_scores = cust_iforest_anomaly(df)\n",
    "\n",
    "    reg_anomaly_dict = flattened(df)\n",
    "\n",
    "    pairs_anomaly_dict = pairs_anomaly(df)\n",
    "\n",
    "    sum_anomaly_dict = summarization(df)\n",
    "    \n",
    "    # Anomalous IPs from the Custom Isolation Forest (Flattening)\n",
    "    custForest_anomalous_ips = [(ip, score) for ip, score in custForest_flat_scores.items() if score < 0]\n",
    "     # Anomalous IPs from the Standard Isolation Forest (Flattening)\n",
    "    regForest_anomalous_ips = [(ip, score) for ip, score in reg_anomaly_dict.items() if score < 0]\n",
    "    # Standard Isolation Forest (IP-Port Pairs): (IP, score) pairs for anomalous IPs\n",
    "    pairs_anomalous_ips = [(ip, score) for ip, score in pairs_anomaly_dict.items() if score < 0]\n",
    "    # Standard Isolation Forest (Summarization): (IP, score) pairs for anomalous IPs\n",
    "    sum_anomalous_ips = [(ip, score) for ip, score in sum_anomaly_dict.items() if score < 0]\n",
    "    # endregion\n",
    "\n",
    "    # region F2 scores\n",
    "    # Calculate metrics for each method\n",
    "    custom_prec, custom_rec, custom_f2 = calculate_metrics(anomalous_ips, custForest_anomalous_ips)\n",
    "    reg_prec, reg_rec, reg_f2 = calculate_metrics(anomalous_ips, regForest_anomalous_ips)\n",
    "    pairs_prec, pairs_rec, pairs_f2 = calculate_metrics(anomalous_ips, pairs_anomalous_ips)\n",
    "    sum_prec, sum_rec, sum_f2 = calculate_metrics(anomalous_ips, sum_anomalous_ips)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics_custom['precision'].append(custom_prec)\n",
    "    metrics_custom['recall'].append(custom_rec)\n",
    "    metrics_custom['f2'].append(custom_f2)\n",
    "\n",
    "    metrics_reg['precision'].append(reg_prec)\n",
    "    metrics_reg['recall'].append(reg_rec)\n",
    "    metrics_reg['f2'].append(reg_f2)\n",
    "    \n",
    "    metrics_pairs['precision'].append(pairs_prec)\n",
    "    metrics_pairs['recall'].append(pairs_rec)\n",
    "    metrics_pairs['f2'].append(pairs_f2)\n",
    "    \n",
    "    metrics_sum['precision'].append(sum_prec)\n",
    "    metrics_sum['recall'].append(sum_rec)\n",
    "    metrics_sum['f2'].append(sum_f2)    \n",
    "    # endregion\n",
    "\n",
    "    # Store all information in the experiment dictionary\n",
    "    exp = {\n",
    "        'seed': seed,\n",
    "        'num_ips': num_ips,\n",
    "        'num_scans_per_ip': num_scans_per_ip,\n",
    "        \"Custom iForest Flattening scores\": custForest_flat_scores,\n",
    "        \"iForest Pairs scores\": pairs_anomaly_dict,\n",
    "        \"iForest Summarization scores\": sum_anomaly_dict,\n",
    "        \"Actual Anomalous IPs\": anomalous_ips,\n",
    "        \"Custom iForest Anomalous IPs\": custForest_anomalous_ips,\n",
    "        \"iForest Pairs Anomalous IPs\": pairs_anomalous_ips,\n",
    "        \"iForest Summarization Anomalous IPs\": sum_anomalous_ips,\n",
    "        \"Custom iForest F2-Score\": custom_f2,\n",
    "        \"iForest Pairs F2-Score\": custom_f2,\n",
    "        \"iForest Summarization F2-Score\": custom_f2\n",
    "    }\n",
    "    \n",
    "    # Add the experiment dictionary to the list of all experiments\n",
    "    all_exp.append(exp)\n",
    "\n",
    "#region Print all experiments for verification\n",
    "'''\n",
    "for experiment in all_exp:\n",
    "    for key, value in experiment.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"-\" * 20)  # Separator between experiments\n",
    "    '''\n",
    "#endregion\n",
    "\n",
    "# Calculate averages\n",
    "avg_metrics = {\n",
    "    'Custom iForest': {\n",
    "        'Precision': mean(metrics_custom['precision']),\n",
    "        'Recall': mean(metrics_custom['recall']),\n",
    "        'F2-Score': mean(metrics_custom['f2'])\n",
    "    },\n",
    "    'iForest Flattened': {\n",
    "        'Precision': mean(metrics_reg['precision']),\n",
    "        'Recall': mean(metrics_reg['recall']),\n",
    "        'F2-Score': mean(metrics_reg['f2'])\n",
    "    },\n",
    "    'iForest Pairs': {\n",
    "        'Precision': mean(metrics_pairs['precision']),\n",
    "        'Recall': mean(metrics_pairs['recall']),\n",
    "        'F2-Score': mean(metrics_pairs['f2'])\n",
    "    },\n",
    "    'iForest Summarization': {\n",
    "        'Precision': mean(metrics_sum['precision']),\n",
    "        'Recall': mean(metrics_sum['recall']),\n",
    "        'F2-Score': mean(metrics_sum['f2'])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create and display results table\n",
    "results_df = pd.DataFrame(avg_metrics).round(3)\n",
    "print(\"\\nAverage Performance Metrics:\")\n",
    "print(\"-\" * 63)\n",
    "print(results_df)\n",
    "print(\"-\" * 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(3, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iForest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
